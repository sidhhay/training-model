## Goal: By the end of this notebook, you'll understand exactly what happens when someone says "the model is training." No magic, no hand-waving.

We'll build a neural network using only NumPy (basic math), train it to solve a problem that a single neuron cannot solve, and then see how PyTorch automates what we did manually.

What We'll Cover
# The XOR Problem — Why we need hidden layers
# Building a Neural Network — Forward pass from scratch
# The Training Loop — Loss, backprop, weight updates
# Watching It Learn — Visualizing training
# Breaking It — What happens with bad hyperparameters
# PyTorch Version — Same thing, less code
